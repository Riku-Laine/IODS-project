- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using  

# Data analysis for IODS week 2

```{r Data input, echo=F}
# Setting working directory with knitr.
library(knitr)
library(GGally)

opts_knit$set(root.dir ="C:/Users/Riku_L/Documents/GitHub/IODS-project/data")

# Read data

students2014 <- read.csv("data/learning2014.csv")

```

The data has been read into the system and it has been collected 3.12.2014 -- 10.1.2015. The original results were from an international survey of Approaches to Learning. The following data includes variables as described in [here](https://www.slideshare.net/kimmovehkalahti/the-relationship-between-learning-approaches-and-students-achievements-in-an-introductory-statistics-course-in-finland). The summary variables (such as *deep_adj*) answer to questions like how deeply the individual is trying to learn and how organized is his/her studying.

Next, I will briefly examine the data set's dimensions and structure.

```{r Dimensions and structure}

# First six rows of the data set
head(students2014)

# The dimensions
dim(students2014)

# Type of variables
str(students2014)

# SummarÃ­es of the variables included in the data
summary(students2014)


```

So, from the above we can conclude that the data has 166 observations and each observation consists of 7 variables as the data frame has 166 rows and 7 columns. The data consists of mainly numerical information on the respondents

* gender (coded as M for males and F for females)
* age
* global attitude toward statistics
* points in the final exam 
* measures for
    + deep learning
    + how surfaced is the learning (emphasis in learning single, separate pieces of information)
    + strategic learning.

Of the respondents 110 identified themselves as female and 56 as male. Respondents were 17--55 years old and half of them were 21--27 years old. They got an average of 22.72 points on the final exam and were somewhat deep learners ($\mu$ = 3.68). You could say they tend to be strategic learners, because upon implementing a t-test for the mean of Stra_adj, I discovered that the mean differs significantly from 3 ($p \approx 0.446$). The t-test is a classical statistic test which tests if the mean from a group of measurements differs from a values "just by chance".

The sum variables (`r paste(colnames(students2014)[4:7], sep=', ')`) were created as instructed by [Kimmo](http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt). 

## Graphical overview

First, we will construct pairwise plots of each variable and draw bigger histograms to see the variables' distribution.

```{r Plots, echo = F, out.width="\\maxwidth", out.height="\\maxheight", message=FALSE}
par(mfrow=c(3,2))
for (i in 2:7) hist(students2014[,i], main = colnames(students2014)[i], xlab = NULL)
par(mfrow=c(1,1))

ggpairs(students2014[,-1])

ggpairs(students2014, mapping=ggplot2::aes(colour=gender, alpha = 0.4))
```

Summaries were printed in the previous section, but here we clearly see how the distribution of ages is heavily skewed to the left whereas other variables have approximately symmetrical distributions. From the plot matrix, we can conclude that none of the variables correlate with each other much as the highest absolute correlation of 0.437 is with Points and Attitude which would be classified as weak positive correlation.

From the lower matrix it is also visible that males seem to have a bit better attitude toward statistics and that women tend to be more methodological with their approach to studying.

## Regression

Let's perform a linear regression where we assume that there is a linear dependency between the dependent variable and the explanatory variables. Linear model can be expressed as $$y = \alpha + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon$$ where $x_1, x_2, x_3$ are the values of the explanatory variables and $y$ the value of the dependent variable. Epsilon is considered as the error parameter or *residuals*, which should be normally distributed, $\epsilon \sim N(0,\sigma^2)$. The residuals are examined via the diagnostic plots.

```{r Regression, echo =F}

# Model itself
model <- lm(Points ~ Attitude + Age + Stra_adj, data = students2014)

# Summary
summary(model)
```

From the summary it is visible that only attitude raises -- or affects -- performance in the final exam on 5 per cent significance level. For every attitude point gained it is estimated that an average of 0.35 exam points is achieved. We also notice from the output that age has the least significant effect on our model so we remove it from the model.

```{r Update model}
# Remove variable age by update() function
model <- update(model, formula. = .~. - Age)

summary(model)
```

*Using a summary of your fitted model, explain the relationship between the chosen explanatory variables and the target variable (interpret the model parameters). Explain and interpret the multiple R squared of the model.*

From the summary of the model we see that one could get approximately 9 points from the final exam with zero attitude and no strategy in learning. We can conclude that attitude has a very significant effect, which stays in the same level as in the previous model. The p-value given tests against the null hypothesis that the coefficient of the variable is zero (alpha, beta or gamma in the equation above). And as is seen, for every 1 point of attitude the score on the final exam rises approximately 0.35 points.

The R-squared of the output tells us how well our model explains the variability of the dependent variable. In this case, our model explains roughly 20.5 per cent of the variability, which is quite bad. According to some sources the $R^2$ should be around 0.40 -- 0.60.

## Diagnostics

Let's produce the diagnostic plots:

```{r Diagnostics, echo=F}
plot(model, which=c(1,2,5))
```

As was previously explained, the linear model relies on the fact that the residuals are normally distributed. The QQ-plot tells us that the assumption is slightly off: the residuals' left tail seems to be okay as we only have 4 observations lying off the quantile-quantile-line whilst the right tail is slightly heavy. When distributions right tail is "heavy", it means that it has more mass in there as the model predicts. The other plots show also no significant deviation from the assumptions that the residuals don't depend on the fitted values.